---
title: "Final Project: Bike Sharing Dataset"
author: "Northeastern: ALY 6015 G. Holt Williams and Aniruddha Sanjay Pazare"
date: "6/28/2020"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.width=12, fig.height = 7)
library(printr)
library(ggthemes)
```

# Introduction

The purpose of this assignment is to showcase the material the group learned throughout ALY 6015. This is accomplished first through exploratory data analysis of a large data set with accompanying tables and data visualizations for emphasis. Second, will be a showcase of statistical hypothesis testing to answer questions that would be relevant to a business. The final section delves into using linear modeling to understand the relationship that different time periods have on the data, followed by regularization methods to determine a more predictive model with all available variables. Each section will compare Casual vs Registered vs Total users.

# Data Import and Cleaning

The following R code imports the dataset and creates factor/date variables for the time variables which will be essential for further analysis. The code also renames all levels for the factor variables for ease of readability. Other useful cleaning steps include making the data “tall” instead of “wide” by combining the Total, Registered, and Casual columns into two columns of type and count.

```{r library, echo=TRUE, message=FALSE, warning=FALSE}
## load Libraries
library(tidyverse)
library(psych)
library(tidymodels)
library(forecast)
## load data
hour<-read.csv("hour.csv")
## Clean and create factor variables
cols<-colnames(hour)[3:10]
hour<-hour%>%mutate_at(cols, funs(factor(.)))
hour$dteday<-as.Date(hour$dteday)
levels(hour$season)<-c("Winter","Spring","Summer","Fall")
levels(hour$yr)<-c("2011","2012")
levels(hour$mnth)<-c("Jan","Feb","Mar","Apr","May","June","July","Aug","Sept","Oct","Nov","Dec")
levels(hour$weekday)<-c("Sun","Mon","Tues","Weds","Thurs", "Fri", "Sat")
levels(hour$weathersit)<-c("Nice","Moderate","LightPercipitation","Dangerous") 
hour<-hour%>%rename(Year=yr,
                    Month=mnth,
                    Total=cnt,
                    Casual=casual,
                    Registered=registered,
                    Holiday=holiday,
                    Weekday=weekday,
                    Humidity=hum,
                    Temperature=temp,
                    Windspeed=windspeed)
long<-hour%>%gather("Type","Count",15:17)
long$Type<-as.factor(long$Type)
```


# Exploratory Data Analysis

This section explores the structure of the data. First is a table with basic summary statistics of the non-time/non-factorized variables. This includes weather variables and the outcome variables Casual, for Casual users, Registered, for Registered users, and Total, for total count of users.

```{r EDA_0, echo=TRUE, message=FALSE, warning=FALSE}
hour[2:17]%>%
  describe(quant=c(.25,.75),omit=TRUE)%>%
  select(n, sd,mean, median, min, max, Q0.25, Q0.75)%>%round(digits=2)
```

According to the authors, the weather variables (Temperature, atemp, Humidity, and Windspeed) have been normalized (Dua 2019). As is evident from the above table, the dataset has 17379 entries of data for every hour over a two-year period.

```{r EDA_1, echo=FALSE, message=FALSE, warning=FALSE, include=FALSE}
c(min(hour$dteday), max(hour$dteday))
```



This period being from `r min(hour$dteday)`  through `r max(hour$dteday)`. Next the analysis digs into the different time periods that are available in this dataset: Yearly, Seasonal, Monthly, and Daily

## Yearly

```{r EDA_2, echo=TRUE, message=FALSE, warning=FALSE, fig.width = 11}
long%>%
  group_by(Type,dteday)%>%
  mutate(sum=sum(Count))%>%
  ggplot(aes(x=dteday,y=sum, color=Type))+
  geom_point(aes(shape=season))+stat_smooth()+ 
  theme_fivethirtyeight()+
  xlab("Time")+
  ylab("Ridership")+ggtitle("Ridership: 2011-2012")
```

```{r EDA_3, echo=TRUE, message=FALSE, warning=FALSE}
hour%>%
  group_by(Year)%>% 
  summarise(Casual=sum(Casual),Registered=sum(Registered),Total=sum(Total))
```

In the above table and chart, overall ridership increases over the two-year time period. The total ridership increases by almost 800,000 trips, that is mostly contained in its Registered users which rose just over 680,000 trips from 2011 to 2012. This increase is likely due to an increase in the quantity of bikes plus the normalization of local populations to using the bicycles as a reliable mode of transportation.



## Seasonal and Monthly

```{r EDA_4, echo=TRUE, message=FALSE, warning=FALSE}
hour%>%
  group_by(Year,season)%>% 
  summarise(Casual=sum(Casual),Registered=sum(Registered),Total=sum(Total))%>%
  knitr::kable()
```

From this table it is easy to see that the winter season features the smallest quantity of riders, which follows logical sense as snow and cold weather can easily dissuade users from taking a bicycle. Similarly, Summer has the highest ridership’s as the weather is more likely to be amenable to biking.


```{r EDA_5, echo=TRUE, message=FALSE, warning=FALSE}
long%>%
  group_by(Type,dteday)%>%
  mutate(sum=sum(Count))%>%
  ggplot(aes(x=sum, y=season, fill=season))+
  geom_boxplot()+
  facet_grid(Year~Type)+
  coord_flip()+
  theme_fivethirtyeight()+theme()+
  xlab("Ridership")+ggtitle("Season by Type of Ridership")
```

In the boxplots we can see this relationship playout with all three groups of data. One interesting takeaway is that mean Casual fall ridership is below mean Casual spring ridership, but this is not the case for Registered ridership. This is most likely due to fewer tourists, who likely have a large impact on Casual ridership, in the fall, as families have kids going back to school. The flip side of this looking at Registered users suggests that many users depend on the bicycles for their daily commutes. This hypothesis becomes more apparent in the daily and hourly sections.

```{r EDA_6, echo=TRUE, message=FALSE, warning=FALSE, fig.width=7}
long%>%
  group_by(Type,dteday)%>%
  mutate(sum=sum(Count))%>%
  ggplot(aes(x=sum, y=Month, fill=season))+
  geom_boxplot()+
  facet_grid(Type~.)+coord_flip()+
  theme_fivethirtyeight()+theme(axis.text.x=element_blank(),
    axis.ticks.x=element_blank())+
  xlab("Ridership")+ylab("Months")+ggtitle("Months by Type of Ridership")
```

Here we see the same patterns discussed above, with the data broken down by each month and season. The extra boxplots are the months where the seasons shift mid-month. One interesting takeaway from this visualization is how in December casual ridership has a very small change from spring to winter, but registered users have a large leap, likely due to Christmas and having days off where they are not commuting but may instead be using a car to travel longer distances.

## Weekly and Daily

```{r EDA_7, echo=TRUE, message=FALSE, warning=FALSE}
long%>%
  group_by(Type,dteday)%>%
  mutate(sum=sum(Count))%>%
  ggplot(aes(x=sum, y=Weekday, fill=Weekday))+
  geom_boxplot()+
  facet_wrap(~Type)+coord_flip()+
  theme_fivethirtyeight()+theme(axis.text.x=element_blank(),
    axis.ticks.x=element_blank())+
  xlab("Ridership")+ggtitle("Weekday by Type of Ridership")
```

Looking at weekly data, the data begins to show the stark differences in the types of users of the bicycle sharing program. The Registered users have about average ridership from Monday through Friday while the Casual ridership has the opposite pattern. This disparity likely comes from Registered users utilizing the bicycles as their main daily commute to and from work. This theory is confirmed when looking at the different times of day that ridership is high for the two groups. The casual ridership spikes on the weekends as that is when casual users have free time during sunlight hours


```{r EDA_8, echo=TRUE, message=FALSE, warning=FALSE, fig.height=10, fig.width=14}
long%>%
  group_by(Type)%>%
  ggplot(aes(x=Count, y=hr, fill=hr))+
  geom_boxplot()+
  facet_wrap(Holiday~Type)+
coord_flip()+
  theme_fivethirtyeight()+theme(axis.text.x=element_blank(),
    axis.ticks.x=element_blank())+
  xlab("Ridership")+ylab("Hour")+ggtitle("Hour by Type of Ridership")
```

Here is visualization with a few dimensions. From left to right is the day broken down into 24 hours by each type of riders, which is then facetted by a day being a Holiday from top to bottom. Looking at the top, the daily commute of registered riders is highest during normal commute hours, whereas casual users don’t tend to start using the cycles until 10 at a sustained level till night. While looking at the holiday section the fact that registered users use the bicycles is reconfirmed as the spike during commute hours is no longer present. That time is still higher than casual users, but this is likely due to the few registered users who still must work on Holidays. Interestingly, casual users have a higher ridership in the middle of the day on Holidays as they likely don’t have to work on those days.




# Hypothesis Testing

Next, is a few hypothesis tests to explore the output variables. First will be a t-test with the following hypothesis and outputs

Ho: The mean ridership of Registered and Casual users is equal

Ha: The mean ridership of Registered and Casual users is not equal

alpha = 0.05


```{r t.test_0, echo=TRUE}
t.test(value~key ,  data=gather(hour[15:16]))
```

t: -97.813

P-value: < 2.2e-16

Using a two-sample t-test where the null is that there is no difference in mean ridership of Registered and Casual users, the outcome is a p-value less than 0.05, which means the null hypothesis is rejected at the 95% confidence interval.

This was an expected outcome as Registered users receive a better deal on bikes and are more likely to live in the area and use the bikes as a daily or weekly commute vehicle, versus Casual users are more likely to use the bikes for one off adventures. Because this was an expected outcome, it would be prudent to perform an f-test to the variance of the ridership’s between Casual and Registered.

Ho: There is no difference between the variances of ridership of Registered and Casual users

Ha: There is a difference between the variances of ridership of Registered and Casual users

alpha = 0.05


```{r ftest_0, echo=TRUE}
var.test(value~key ,  data=gather(hour[15:16]))
```

F: 0.10611

P-value: < 2.2e-16

Utilizing an f-test to test if there is a difference in the variances of the ridership has a p-value less than 0.05. This means the null hypothesis is rejected at a 95% confidence interval, the null hypothesis being that the difference is zero, while the alternative hypothesis is that the difference is not equal to zero. This is an unsurprising result after exploring the visualizations of the two types of ridership. Registered users more often utilize the bikes for daily commuting, while Casual users are more likely to use them for more one-off instances and will not have the same reliance on the bicycles resulting in different variances.




# Modelling


## Model Creation and Analysis: Time Variables

The next section delves into the relationship that different time periods have on the different types of ridership. This will be explored by comparing a model with all-time variables versus multiple models using just one time variable.

Utilizing the tidyverse set of functions, specifically the broom and purr packages a list data frame grouped by each type of ridership with models for Year, Season, Month, Weekday, and Hour is created.


```{r model_0, echo=TRUE, warnings=FALSE}
# Packages

# Nest Data
test<- long%>%group_by(Type)%>%nest()
# Define Models
ALL_model <- function(df) {
  lm(Count ~ Year+season+Month+Weekday+hr, data = df)
} 
yr_model <- function(df) {
  lm(Count ~ Year, data = df)
}
season_model <- function(df) {
  lm(Count ~ season, data = df)
}
mnth_model <- function(df) {
  lm(Count ~ Month, data = df)
} 
Weekday_model <- function(df) {
  lm(Count ~ Weekday, data = df)
} 
hr_model <- function(df) {
  lm(Count ~ hr, data = df)
} 
# Apply models
test <- test%>% 
  mutate(ALL_model = map(data, ALL_model))
test <- test%>% 
  mutate(yr_model = map(data, yr_model))
test <- test%>% 
  mutate(season_model = map(data, season_model))
test <- test%>% 
  mutate(mnth_model = map(data, mnth_model))
test <- test%>% 
  mutate(Weekday_model = map(data, Weekday_model))
test <- test%>% 
  mutate(hr_model = map(data, hr_model))
test[c(1,3:8)]
```

The above table features each model created and the comparisons are delved into below.

## Model Outputs

Linear modelling was utilized to compare different models possible using the multiple time variables in the dataset. The table contains the R^2, AIC, BIC, and Adjusted R^2 for all the models run. First, a model with all the time variables was run, then models with just singular time variables was run as shown in the table.

```{r model_1, echo=TRUE,message=FALSE, warning=FALSE}
model_table<-test%>%mutate(
  All = map(ALL_model, broom::glance),
  Year= map(yr_model, broom::glance),
  Season= map(season_model, broom::glance),
  Month= map(mnth_model, broom::glance),
  Weekday= map(Weekday_model, broom::glance),
  Hour= map(hr_model, broom::glance)
)
output_table<-model_table[9:14]%>%unnest(c(All,Year,Season,Month,Weekday,Hour),names_sep=".", .drop = TRUE)%>%
  select(matches("r.squared"),matches("AIC"),matches("BIC"))

tidy(t(output_table))%>%arrange(.rownames)%>%rename(Model.by.Statistic=.rownames, Causal=X1, Registered=X2, Total=X3)

```

From the table one can see that overall just using time in different formats does not create a strong model. Interpreting the All model from here, one can say the model predicted 65% of the variation (R^2) when applied to the Total ridership. Next, the terms, estimates, and p-values of the Season model are shown and interpreted.

```{r model_2, echo=TRUE,message=FALSE, warning=FALSE}
test %>% 
  mutate(tidy = map(season_model, broom::tidy)) %>% 
  unnest(tidy, .drop = TRUE)%>%select(term,estimate, p.value)

```

The above estimates show the same patterns seen in the previous visualizations. The casual model has summer and spring both estimating twice as much of an impact to fall when compared against the winter, while the registered model has fall having a greater impact on ridership than spring when compared to the winter season. All the terms are statistically significant at the 95% confidence interval when looking over the p-value.

## Forecasting: Arima and TBATS

The previous sections of this analysis focused on identifying the trends through visualization and linear modelling, but the upcoming section will explore time series analysis with auto.arima and TBATS models. The following code chunks creates the time series required for analysis

```{r ts_1, echo=TRUE, warnings=FALSE}
# Packages
Casual<-long[c(15:16)]%>%filter(Type=="Casual")
Casual<-Casual[2]
Registered<-long[c(15:16)]%>%filter(Type=="Registered")
Registered<-Registered[2]
Total<-long[c(15:16)]%>%filter(Type=="Total")
Total<-Total[2]
casual_ts<-ts(Casual)
Registered_ts<-ts(Registered)
Total_ts<-ts(Total)
```


This section utilizes the autoArima() function in R to forecast the next 72 hours:


```{r ts_2, echo=TRUE,message=FALSE, warning=FALSE, fig.height=7}
Casual_arima<-auto.arima(casual_ts)
autoplot(forecast(Casual_arima, h=72))+
  coord_cartesian(xlim = c(nrow(Casual)-720, nrow(Casual)+72))

Registered_arima<-auto.arima(Registered_ts)
autoplot(forecast(Registered_arima, h=72))+
  coord_cartesian(xlim = c(nrow(Casual)-720, nrow(Casual)+72))

Total_arima<-auto.arima(Total_ts)
autoplot(forecast(Total_arima, h=72))+
  coord_cartesian(xlim = c(nrow(Casual)-720, nrow(Casual)+72))

```

The Casual model looks to capture the daily trend the best, followed by the Registered and Total models. This is not too surprising as the Casual ridership was overall less influenced by Holidays and other specified seasonal events. Next a TBATS model is utilized to try and pull out further seasonality trends that may have been missed through the autoARIMA() function.

```{r ts_3, echo=TRUE,message=FALSE, warning=FALSE, fig.height=7}
casual_tbats<-tbats(casual_ts)
autoplot(forecast(casual_tbats, h=72))+
  coord_cartesian(xlim = c(nrow(Casual)-720, nrow(Casual)+72))

Registered_tbats<-tbats(Registered_ts)
autoplot(forecast(Registered_tbats, h=72))+
  coord_cartesian(xlim = c(nrow(Casual)-720, nrow(Casual)+72))

Total_tbats<-tbats(Total_ts)
autoplot(forecast(Total_tbats, h=72))+
  coord_cartesian(xlim = c(nrow(Casual)-720, nrow(Casual)+72))

```

Overall, using time series analysis with autroARIMA() and TBATS() to predict hourly usage is difficult due to the many trends that occur throughout the year that were explored earlier in the report. Examples would be the season change with winter having the smallest change, down to the hourly changes where it spikes during commuting hours for registered users and when usage is around zero in the early morning before sunrise. Interestingly, the TBATS() function used on the Total Ridership is the only automated model that understands ridership will not go negative. Using the chosen model there on the other ridership Types may produce interesting results and would be a subject of future study.
It is also possible to transform the dataset into daily data and perform the TBATS() function on the daily ridership, which produced similar model results for Casual Ridership as the Hourly Total Ridership above.

It is also possible to transform the dataset into daily data and perform the TBATS() function on the daily ridership, which produced simialr model results for Casual Ridership as the Hourly Total Ridership above. 

```{r ts_5, echo=TRUE,message=FALSE, warning=FALSE, fig.height=7}
Casual_day<-long%>%group_by(Type,dteday)%>%summarise(day_cnt=sum(Count))%>%filter(Type=="Casual")
Casual_day<-Casual_day[3]%>%ts(frequency=7)
Casual_arima<-tbats(Casual_day)
autoplot(forecast(Casual_arima, h=90))

day<-long%>%group_by(Type,dteday)%>%summarise(day_cnt=sum(Count))%>%filter(Type=="Registered")
day<-day[3]%>%ts(frequency=7)
arima<-tbats(day)
autoplot(forecast(arima, h=90))

day<-long%>%group_by(Type,dteday)%>%summarise(day_cnt=sum(Count))%>%filter(Type=="Total")
day<-day[3]%>%ts(frequency=7)
arima<-tbats(day)
autoplot(forecast(arima, h=90))

```

Using the two models above which produced predictions above zero can be useful to predict the usage for the next day, which is a business problem bikeshare companies will come across. Understanding their market and timing bike repairs and expanding inventory is a crucial element to ensure riders can rely on the bike sharing company for their daily commute requirements.


# References

[1] Dua, D. and Graff, C. (2019). UCI Machine Learning Repository [http://archive.ics.uci.edu/ml]. Irvine, CA: University of California, School of Information and Computer Science.

[2] Fanaee-T, Hadi, and Gama, Joao, 'Event labeling combining ensemble detectors and background knowledge', Progress in Artificial Intelligence (2013): pp. 1-15, Springer Berlin Heidelberg

Web Source: http://archive.ics.uci.edu/ml/datasets/Bike+Sharing+Dataset


